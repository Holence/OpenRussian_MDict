{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import *\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "\n",
    "def show_na_column(df):\n",
    "    print(\"NaN:\", [i for i in list(df.isnull().sum().items()) if i[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.read_csv(\"openrussian_public/openrussian_public - words.csv\", usecols=[\"id\", \"bare\", \"accented\", \"derived_from_word_id\", \"rank\", \"disabled\", \"usage_en\", \"type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 有些词竟然还有多余的空格……\n",
    "print(\"Check Space:\")\n",
    "print(words[\"bare\"].str.contains(\" $\").sum())\n",
    "print(words[\"bare\"].str.contains(\"^ \").sum())\n",
    "\n",
    "print(\"After strip()\")\n",
    "words[\"bare\"] = words[\"bare\"].apply(lambda x: x.strip())\n",
    "print(words[\"bare\"].str.contains(\" $\").sum())\n",
    "print(words[\"bare\"].str.contains(\"^ \").sum())\n",
    "\n",
    "print(\"Check Space:\")\n",
    "print(words[\"accented\"].str.contains(\" $\").sum())\n",
    "print(words[\"accented\"].str.contains(\"^ \").sum())\n",
    "\n",
    "print(\"After strip()\")\n",
    "words[\"accented\"] = words[\"accented\"].apply(lambda x: x.strip())\n",
    "print(words[\"accented\"].str.contains(\" $\").sum())\n",
    "print(words[\"accented\"].str.contains(\"^ \").sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words[\"derived_from_word_id\"] = words[\"derived_from_word_id\"].fillna(-1)\n",
    "words[\"rank\"] = words[\"rank\"].fillna(-1)\n",
    "words[\"accented\"] = words[\"accented\"].map(convertStress)\n",
    "words[\"usage_en\"] = words[\"usage_en\"].fillna(\"\")\n",
    "words[\"usage_en\"] = words[\"usage_en\"].replace(\"\\\\\\\\n\", \"\\\\n\", regex=True)\n",
    "dtype = {\"id\": \"int\", \"bare\": \"string\", \"accented\": \"string\", \"derived_from_word_id\": \"int\", \"rank\": \"int\", \"disabled\": \"int\", \"usage_en\": \"string\", \"type\": \"string\"}\n",
    "words = words.astype(dtype)\n",
    "words.info()\n",
    "show_na_column(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_nan_list = words[~pd.isna(words[\"type\"])]\n",
    "print(\"Total Not NaN:\", len(not_nan_list))\n",
    "print(\"Total Not NaN (not disabled):\", len(not_nan_list[not_nan_list[\"disabled\"] == 0]))\n",
    "print(\"Total Not NaN (disabled):\", len(not_nan_list[not_nan_list[\"disabled\"] == 1]))\n",
    "not_nan_list = not_nan_list[not_nan_list[\"disabled\"] == 1]\n",
    "print(\"Has Usage (disabled):\", len(not_nan_list[not_nan_list[\"usage_en\"].isna() == False]))\n",
    "del not_nan_list\n",
    "\n",
    "print()\n",
    "nan_list = words[pd.isna(words[\"type\"])]\n",
    "print(\"Total NaN:\", len(nan_list))\n",
    "print(\"Total NaN (not disabled):\", len(nan_list[nan_list[\"disabled\"] == 0]))\n",
    "print(\"Total NaN (disabled):\", len(nan_list[nan_list[\"disabled\"] == 1]))\n",
    "nan_list = nan_list[nan_list[\"disabled\"] == 0]\n",
    "print(\"Has Usage (not disabled):\", len(nan_list[nan_list[\"usage_en\"].isna() == False]))\n",
    "del nan_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disabled的词、type为NaN的词，将没有主页面，但是可以被relate到\n",
    "selected_words = words[~pd.isna(words[\"type\"])].copy(deep=True)\n",
    "selected_words = selected_words[selected_words[\"disabled\"] == 0]\n",
    "selected_words = selected_words.drop(columns=[\"disabled\"])\n",
    "selected_words.info()\n",
    "show_na_column(selected_words)\n",
    "selected_words_dict = selected_words.set_index(\"id\").to_dict(\"index\")\n",
    "del selected_words\n",
    "\n",
    "other_words = words[(pd.isna(words[\"type\"])) | (words[\"disabled\"] == 1)].copy(deep=True)\n",
    "other_words = other_words.drop(columns=[\"bare\", \"derived_from_word_id\", \"rank\", \"disabled\", \"usage_en\", \"type\"])\n",
    "other_words.info()\n",
    "show_na_column(other_words)\n",
    "other_words_dict = other_words.set_index(\"id\").to_dict(\"index\")\n",
    "del other_words\n",
    "\n",
    "del words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_forms_csv = pd.read_csv(\"openrussian_public/openrussian_public - words_forms.csv\", usecols=[\"word_id\", \"form_type\", \"form\"])\n",
    "words_forms_csv[\"form\"] = words_forms_csv[\"form\"].fillna(\"\")\n",
    "\n",
    "# 有些词竟然还有多余的空格……\n",
    "print(\"Check Space:\")\n",
    "print(words_forms_csv[\"form\"].str.contains(\" $\").sum())\n",
    "print(words_forms_csv[\"form\"].str.contains(\"^ \").sum())\n",
    "\n",
    "print(\"After strip()\")\n",
    "words_forms_csv[\"form\"] = words_forms_csv[\"form\"].apply(lambda x: x.strip())\n",
    "print(words_forms_csv[\"form\"].str.contains(\" $\").sum())\n",
    "print(words_forms_csv[\"form\"].str.contains(\"^ \").sum())\n",
    "\n",
    "# 有些词竟然还有多余的括号……\n",
    "print(\"Check Parentheses:\")\n",
    "print(words_forms_csv[\"form\"].str.contains(\"\\)\").sum())\n",
    "print(words_forms_csv[\"form\"].str.contains(\"\\(\").sum())\n",
    "\n",
    "print(\"After strip()\")\n",
    "words_forms_csv[\"form\"] = words_forms_csv[\"form\"].apply(\n",
    "    lambda x: x.strip(\"()\"))\n",
    "print(words_forms_csv[\"form\"].str.contains(\"\\)\").sum())\n",
    "print(words_forms_csv[\"form\"].str.contains(\"\\(\").sum())\n",
    "\n",
    "words_forms_csv[\"form\"] = words_forms_csv[\"form\"].map(convertStress)\n",
    "dtype = {\"word_id\": \"int\", \"form_type\": \"string\", \"form\": \"string\"}\n",
    "words_forms_csv = words_forms_csv.astype(dtype)\n",
    "words_forms_csv.info(show_counts=True)\n",
    "show_na_column(words_forms_csv)\n",
    "\n",
    "print(\"Builing Word Form Dict...\")\n",
    "words_forms_csv_dict = {}\n",
    "for i, row in tqdm(words_forms_csv.iterrows(), total=len(words_forms_csv)):\n",
    "    word_id = row[\"word_id\"]\n",
    "    if words_forms_csv_dict.get(word_id) == None:\n",
    "        words_forms_csv_dict[word_id] = {}\n",
    "\n",
    "    form_type = row[\"form_type\"]\n",
    "    form = row[\"form\"]\n",
    "    if words_forms_csv_dict[word_id].get(form_type) == None:\n",
    "        words_forms_csv_dict[word_id][form_type] = form\n",
    "    else:\n",
    "        words_forms_csv_dict[word_id][form_type] += \", \"+form\n",
    "\n",
    "del words_forms_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_rels_csv = pd.read_csv(\"openrussian_public/openrussian_public - words_rels.csv\", usecols=[\"word_id\", \"rel_word_id\", \"relation\"])\n",
    "dtype = {\"word_id\": \"int\", \"rel_word_id\": \"int\", \"relation\": \"string\"}\n",
    "words_rels_csv = words_rels_csv.astype(dtype)\n",
    "words_rels_csv.info()\n",
    "show_na_column(words_rels_csv)\n",
    "\n",
    "print(\"Builing Word Relation Dict...\")\n",
    "words_rels_csv_dict = {}\n",
    "for i, row in tqdm(words_rels_csv.iterrows(), total=len(words_rels_csv)):\n",
    "    word_id = row[\"word_id\"]\n",
    "    rel_word_id = row[\"rel_word_id\"]\n",
    "    relation = row[\"relation\"]\n",
    "\n",
    "    if words_rels_csv_dict.get(word_id) == None:\n",
    "        words_rels_csv_dict[word_id] = {\n",
    "            \"related\": [],\n",
    "            \"synonym\": [],\n",
    "            \"antonym\": []\n",
    "        }\n",
    "    if rel_word_id not in words_rels_csv_dict[word_id][relation]:\n",
    "        words_rels_csv_dict[word_id][relation].append(rel_word_id)\n",
    "\n",
    "    if words_rels_csv_dict.get(rel_word_id) == None:\n",
    "        words_rels_csv_dict[rel_word_id] = {\n",
    "            \"related\": [],\n",
    "            \"synonym\": [],\n",
    "            \"antonym\": []\n",
    "        }\n",
    "    if word_id not in words_rels_csv_dict[rel_word_id][relation]:\n",
    "        words_rels_csv_dict[rel_word_id][relation].append(word_id)\n",
    "\n",
    "del words_rels_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns_csv = pd.read_csv(\"openrussian_public/openrussian_public - nouns.csv\")\n",
    "# both->b\n",
    "nouns_csv[\"gender\"] = nouns_csv[\"gender\"].map({\"f\": \"f\", \"m\": \"m\", \"n\": \"n\", \"pl\": \"pl\", \"both\": \"b\"})\n",
    "nouns_csv[\"gender\"] = nouns_csv[\"gender\"].fillna(\"\")\n",
    "nouns_csv[\"partner\"] = nouns_csv[\"partner\"].fillna(\"\")\n",
    "nouns_csv[\"partner\"] = nouns_csv[\"partner\"].map(convertStress)\n",
    "nouns_csv[\"animate\"] = nouns_csv[\"animate\"].fillna(0)\n",
    "nouns_csv[\"indeclinable\"] = nouns_csv[\"indeclinable\"].fillna(0)\n",
    "nouns_csv[\"sg_only\"] = nouns_csv[\"sg_only\"].fillna(0)\n",
    "nouns_csv[\"pl_only\"] = nouns_csv[\"pl_only\"].fillna(0)\n",
    "dtype = {\"word_id\": \"int\", \"gender\": \"string\", \"partner\": \"string\", \"animate\": \"bool\", \"indeclinable\": \"bool\", \"sg_only\": \"bool\", \"pl_only\": \"bool\"}\n",
    "nouns_csv = nouns_csv.astype(dtype)\n",
    "nouns_csv.info()\n",
    "show_na_column(nouns_csv)\n",
    "\n",
    "nouns_csv_dict = nouns_csv.set_index(\"word_id\").to_dict(\"index\")\n",
    "del nouns_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs_csv = pd.read_csv(\"openrussian_public/openrussian_public - verbs.csv\", usecols=[\"word_id\", \"aspect\", \"partner\"])\n",
    "# imperfective->i, perfective->p, both->b\n",
    "verbs_csv[\"aspect\"] = verbs_csv[\"aspect\"].map({\"imperfective\": \"i\", \"perfective\": \"p\", \"both\": \"b\"})\n",
    "verbs_csv[\"aspect\"] = verbs_csv[\"aspect\"].fillna(\"\")\n",
    "\n",
    "\n",
    "def func(s):\n",
    "    return convertStress(s).replace(\";\", \", \")\n",
    "\n",
    "\n",
    "verbs_csv[\"partner\"] = verbs_csv[\"partner\"].fillna(\"\")\n",
    "verbs_csv[\"partner\"] = verbs_csv[\"partner\"].map(func)\n",
    "\n",
    "dtype = {\"word_id\": \"int\", \"aspect\": \"string\", \"partner\": \"string\"}\n",
    "verbs_csv = verbs_csv.astype(dtype)\n",
    "verbs_csv.info()\n",
    "show_na_column(verbs_csv)\n",
    "\n",
    "verbs_csv_dict = verbs_csv.set_index(\"word_id\").to_dict(\"index\")\n",
    "del verbs_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expressions_words_csv = pd.read_csv(\"openrussian_public/openrussian_public - expressions_words.csv\", usecols=[\"expression_id\", \"referenced_word_id\"])\n",
    "dtype = {\"expression_id\": \"int\", \"referenced_word_id\": \"int\"}\n",
    "expressions_words_csv = expressions_words_csv.astype(dtype)\n",
    "expressions_words_csv.info()\n",
    "show_na_column(expressions_words_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translations_csv = pd.read_csv(\"openrussian_public/openrussian_public - translations.csv\")\n",
    "# 只留英语的翻译\n",
    "translations_csv = translations_csv[translations_csv[\"lang\"] == \"en\"]\n",
    "translations_csv = translations_csv.drop(columns=[\"id\", \"lang\", \"position\"])\n",
    "translations_csv[\"example_ru\"] = translations_csv[\"example_ru\"].fillna(\"\")\n",
    "translations_csv[\"example_ru\"] = translations_csv[\"example_ru\"].map(convertStress)\n",
    "translations_csv[\"example_tl\"] = translations_csv[\"example_tl\"].fillna(\"\")\n",
    "translations_csv[\"tl\"] = translations_csv[\"tl\"].fillna(\"\")\n",
    "translations_csv[\"info\"] = translations_csv[\"info\"].fillna(\"\")\n",
    "dtype = {\"word_id\": \"int\", \"tl\": \"string\", \"example_ru\": \"string\", \"example_tl\": \"string\", \"info\": \"string\"}\n",
    "translations_csv = translations_csv.astype(dtype)\n",
    "translations_csv.info()\n",
    "show_na_column(translations_csv)\n",
    "\n",
    "print(\"Builing Word Translation Dict...\")\n",
    "translations_csv_dict = {}\n",
    "for i, row in tqdm(translations_csv.iterrows(), total=len(translations_csv)):\n",
    "    word_id = row[\"word_id\"]\n",
    "    if translations_csv_dict.get(word_id) == None:\n",
    "        translations_csv_dict[word_id] = []\n",
    "\n",
    "    translations_csv_dict[word_id].append([\n",
    "        row[\"tl\"],\n",
    "        row[\"example_ru\"],\n",
    "        row[\"example_tl\"],\n",
    "        row[\"info\"],\n",
    "    ])\n",
    "\n",
    "del translations_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_translations_csv = pd.read_csv(\"openrussian_public/openrussian_public - sentences_translations.csv\", usecols=[\"sentence_id\", \"tl_en\"])\n",
    "sentences_translations_csv = sentences_translations_csv[sentences_translations_csv[\"tl_en\"].isna() == False]\n",
    "dtype = {\"sentence_id\": \"int\", \"tl_en\": \"string\"}\n",
    "sentences_translations_csv = sentences_translations_csv.astype(dtype)\n",
    "sentences_translations_csv.info()\n",
    "show_na_column(sentences_translations_csv)\n",
    "\n",
    "sentences_translations_csv_dict = sentences_translations_csv.set_index(\"sentence_id\").to_dict(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_csv = pd.read_csv(\"openrussian_public/openrussian_public - sentences.csv\", usecols=[\"id\", \"ru\"])\n",
    "dtype = {\"id\": \"int\", \"ru\": \"string\"}\n",
    "sentences_csv = sentences_csv.astype(dtype)\n",
    "# 剔除没有翻译的\n",
    "sentences_csv = sentences_csv[sentences_csv[\"id\"].isin(sentences_translations_csv[\"sentence_id\"])]\n",
    "sentences_csv[\"ru\"] = sentences_csv[\"ru\"].map(convertStress)\n",
    "sentences_csv.info()\n",
    "show_na_column(sentences_csv)\n",
    "\n",
    "sentences_csv_dict = sentences_csv.set_index(\"id\").to_dict(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_words_csv = pd.read_csv(\"openrussian_public/openrussian_public - sentences_words.csv\", usecols=[\"sentence_id\", \"word_id\"])\n",
    "dtype = {\"sentence_id\": \"int\", \"word_id\": \"int\"}\n",
    "sentences_words_csv = sentences_words_csv.astype(dtype)\n",
    "# 剔除没有翻译的\n",
    "sentences_words_csv = sentences_words_csv[sentences_words_csv[\"sentence_id\"].isin(sentences_translations_csv[\"sentence_id\"])]\n",
    "sentences_words_csv.info(show_counts=True)\n",
    "show_na_column(sentences_words_csv)\n",
    "\n",
    "print(\"Builing Word to Sentence Dict...\")\n",
    "word_to_sentence_dict = {}\n",
    "for i, row in tqdm(sentences_words_csv.iterrows(), total=len(sentences_words_csv)):\n",
    "    word_id = row[\"word_id\"]\n",
    "    if word_to_sentence_dict.get(word_id) == None:\n",
    "        word_to_sentence_dict[word_id] = [row[\"sentence_id\"]]\n",
    "    else:\n",
    "        word_to_sentence_dict[word_id].append(row[\"sentence_id\"])\n",
    "\n",
    "print(\"Builing Sentence Dict...\")\n",
    "sentences_words_csv_dict = {}\n",
    "for word_id in tqdm(word_to_sentence_dict):\n",
    "    sentence_ids = word_to_sentence_dict[word_id]\n",
    "    # 打乱排序\n",
    "    random.shuffle(sentence_ids)\n",
    "    # 取前10个\n",
    "    sentence_ids = sentence_ids[:10]\n",
    "    sentences_words_csv_dict[word_id] = []\n",
    "    for sentence_id in sentence_ids:\n",
    "        sentences_words_csv_dict[word_id].append([\n",
    "            sentences_csv_dict[sentence_id][\"ru\"],\n",
    "            sentences_translations_csv_dict[sentence_id][\"tl_en\"],\n",
    "        ])\n",
    "\n",
    "del word_to_sentence_dict\n",
    "del sentences_csv\n",
    "del sentences_csv_dict\n",
    "del sentences_words_csv\n",
    "del sentences_translations_csv\n",
    "del sentences_translations_csv_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accented(word_id: int):\n",
    "    accented = \"\"\n",
    "    try:\n",
    "        accented = selected_words_dict[word_id][\"accented\"]\n",
    "    except:\n",
    "        try:\n",
    "            accented = other_words_dict[word_id][\"accented\"]\n",
    "        except:\n",
    "            pass\n",
    "    return accented\n",
    "\n",
    "\n",
    "def get_extra_info(word_id: int, Type: str):\n",
    "    info = {}\n",
    "    if Type == \"noun\":\n",
    "        try:\n",
    "            info = nouns_csv_dict[word_id]\n",
    "        except:\n",
    "            pass\n",
    "    elif Type == \"verb\":\n",
    "        try:\n",
    "            info = verbs_csv_dict[word_id]\n",
    "        except:\n",
    "            pass\n",
    "    return info\n",
    "\n",
    "\n",
    "def get_translations(word_id: int):\n",
    "    translation_list = []\n",
    "    try:\n",
    "        translation_list = translations_csv_dict[word_id]\n",
    "    except:\n",
    "        pass\n",
    "    return translation_list\n",
    "\n",
    "\n",
    "def get_translation_str(word_id: int):\n",
    "    translation_list = []\n",
    "    try:\n",
    "        translation_list = [i[0] for i in translations_csv_dict[word_id]]\n",
    "    except:\n",
    "        pass\n",
    "    return \"; \".join(translation_list)\n",
    "\n",
    "\n",
    "def get_expressions(word_id: int, Type: str):\n",
    "    # 若查的是单词，则返回expression列表\n",
    "    if Type != \"expression\":\n",
    "        expression_list = []\n",
    "        if word_id in expressions_words_csv[\"referenced_word_id\"].values:\n",
    "            expression_id_list = expressions_words_csv[expressions_words_csv[\"referenced_word_id\"] == word_id][\"expression_id\"].values.tolist()\n",
    "            for expression_id in expression_id_list:\n",
    "                expression_list.append([\n",
    "                    get_accented(expression_id),\n",
    "                    get_translation_str(expression_id)\n",
    "                ])\n",
    "        return expression_list\n",
    "    # 若查的是expression，返回单词的列表\n",
    "    else:\n",
    "        part_list = []\n",
    "        if word_id in expressions_words_csv[\"expression_id\"].values:\n",
    "            part_id_list = expressions_words_csv[expressions_words_csv[\"expression_id\"] == word_id][\"referenced_word_id\"].values.tolist()\n",
    "            for part_id in part_id_list:\n",
    "                part_list.append([\n",
    "                    get_accented(part_id),\n",
    "                    get_translation_str(part_id)\n",
    "                ])\n",
    "        return part_list\n",
    "\n",
    "\n",
    "def get_sentences(word_id: int):\n",
    "    sentence_list = []\n",
    "    try:\n",
    "        sentence_list = sentences_words_csv_dict[word_id]\n",
    "    except:\n",
    "        pass\n",
    "    return sentence_list\n",
    "\n",
    "\n",
    "def get_forms(word_id: int):\n",
    "    forms_dict = {}\n",
    "    try:\n",
    "        forms_dict = words_forms_csv_dict[word_id]\n",
    "    except:\n",
    "        pass\n",
    "    return forms_dict\n",
    "\n",
    "\n",
    "def get_relateds(word_id: int):\n",
    "    relateds_word = {\n",
    "        \"related\": [],\n",
    "        \"synonym\": [],\n",
    "        \"antonym\": []\n",
    "    }\n",
    "    try:\n",
    "        relateds_word = words_rels_csv_dict[word_id]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    relateds = {}\n",
    "    for k in relateds_word:\n",
    "        relateds[k] = [[get_accented(v), get_translation_str(v)]for v in relateds_word[k]]\n",
    "    return relateds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = {}\n",
    "print(len(selected_words_dict))\n",
    "\n",
    "for word_id, value in tqdm(selected_words_dict.items()):\n",
    "\n",
    "    bare = value[\"bare\"]\n",
    "    accented = value[\"accented\"]\n",
    "    derived_from_word_id = value[\"derived_from_word_id\"]\n",
    "    rank = value[\"rank\"]\n",
    "    usage_en = value[\"usage_en\"]\n",
    "    Type = value[\"type\"]\n",
    "\n",
    "    if word_dict.get(bare) == None:\n",
    "        word_dict[bare] = []\n",
    "\n",
    "    temp_dict = {\n",
    "        \"id\": word_id,\n",
    "        \"overview\": {\n",
    "            \"type\": Type,\n",
    "            \"accented\": accented,\n",
    "            \"derived_from_word\": get_accented(derived_from_word_id),\n",
    "            \"rank\": rank\n",
    "        },\n",
    "        \"extra\": get_extra_info(word_id, Type),\n",
    "        \"translations\": get_translations(word_id),\n",
    "        \"usage\": usage_en,\n",
    "        \"expressions\": get_expressions(word_id, Type),\n",
    "        \"sentences\": get_sentences(word_id),\n",
    "        \"forms\": get_forms(word_id),\n",
    "        \"relateds\": get_relateds(word_id),\n",
    "    }\n",
    "\n",
    "    word_dict[bare].append(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomJSONizer(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        return bool(obj) \\\n",
    "            if isinstance(obj, np.bool_) \\\n",
    "            else super().default(obj)\n",
    "\n",
    "import os\n",
    "if not os.path.exists(\"output\"):\n",
    "    os.makedirs(\"output\")\n",
    "\n",
    "with open(\"output/dict.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(word_dict, f, ensure_ascii=False, cls=CustomJSONizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
